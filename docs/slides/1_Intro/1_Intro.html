<!DOCTYPE html>
<html>
  <head>
    <title>Course overview</title>
    <meta charset="utf-8">
    <meta name="author" content="Aldo Solari" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Course overview
### Aldo Solari

---





# Outline

* Course overview
* Algorithms and inference
* Variable selection
* Jelly beans cause acne?
* Which party is correlated with economic success?

---
layout: false
class: inverse, middle, center

# Course overview

---

# Teacher

Aldo Solari

**E-mail** aldo.solari@unimib.it

**Web page** https://aldosolari.github.io/

**Office hours** Thursday, 17:30-18:30, room 2030, building U7, II floor

**Course page** https://aldosolari.github.io/SL/

| When | Where | Hours |
|---|---|----|
| Monday | Lab713 | 13:30-16:30 |
| Wednesday | Lab713 | 15:30-18:30 |
| Thursday | Lab713 | 12:30-14:30 |

.center[**Time table**]

---

# The course

* __Big Data__ and __Data Science__ have now become recurring terms in media communication. In response to the growing need to analyze data, the profession of the __data scientist__ has recently emerged

* This course aims to provide __new tools__ for the data scientist

* These tools require __technical skills__ such as 
    - modern statistical methods
    - advanced programming
    
* They also require __professional skills__ such as 
    - communication
    - teamwork
    - problem solving
    - critical thinking

---

# Topics

The topics covered by this course are

* __Advanced statistical/machine learning models__
    - Generalized Additive Models
    - Support Vector Machines
    - Boosting algorithms
    - Ensemble learning
    
* __Large-scale testing__ &amp; __selective inference__

* __High-dimensional inference__
    - sample-splitting inference
    - stability selection
    - knockoffs


---

# Exam

* The exam consists of two parts:

    - __Written exam__ (open-ended and/or closed-ended questions)

    - __Oral exam__, including the __presentation__ of a data science __project__ (homework)
        - Attending students can form a __team__ (max. 3 persons) and present at the end of the course. In this case the oral exam is optional

* The final grade is a weighted average of written exam (1/2) and oral exam (1/2)

* See the [course syllabus](https://aldosolari.github.io/SL/syllabus/syllabus.html) for further informations

---

# Project


* Your final project is to do a __novel data analysis__ to answer a __question__ and write a __blog post__ about it on github

* The blog post should answer:
    1. __What is the question(s) you tried to answer? Why should someone care?__
    
    2. What is the data/how did you get it?
    
    3. How did you answer the questions (e.g. what statistical techniques, etc)?
    
    4. __What are your findings?__

---

# An example

* __Project__: [fitteR happieR](https://www.rcharlie.com/img/posts/fitter-happier/album_chart.html) by [RCharlie](https://www.rcharlie.com/)

* __Question__: which is the most depressing Radiohead song?

* __Data__ : 
    - Spotify API and the R package *spotifyr* to get the *valence* metric (the song's positivity)
    - Genius Lyrics API and the R package *rvest* to get the *lyrics* (text data)

* __Statistics__ : 
    - Sentiment analysis on lyrics to get the % of sad words in a lyric 
    - `$$GloomIndex = \frac{(1-valence)+pctSad*(1+lyricalDensity)}{2}$$`

* __Visualization__ : https://www.rcharlie.com/img/posts/fitter-happier/album_chart.html

* __Answer__: True Love Waits 

---

# An example

* __Project__: [fitteR happieR](https://www.rcharlie.com/img/posts/fitter-happier/album_chart.html) by [RCharlie](https://www.rcharlie.com/)

* __Question__: which is the most depressing Radiohead song?

* __Data__ : 
    - Spotify API and the R package *spotifyr* to get the *valence* metric (the song's positivity)
    - Genius Lyrics API and the R package *rvest* to get the *lyrics* (text data)

* __Statistics__ : 
    - Sentiment analysis on lyrics to get the % of sad words in a lyric 
    - `$$GloomIndex = \frac{(1-valence)+pctSad*(1+lyricalDensity)}{2}$$`

* __Visualization__ : https://www.rcharlie.com/img/posts/fitter-happier/album_chart.html

* __Answer__: True Love Waits 

---

layout: false
class: inverse, middle, center

# Algorithms and inference

---

# Algorithms and inference

Statistics is the science of *learning from experience*:

* the successes and failures of a new
experimental drug

* the uncertain measurements of an asteroid’s path toward
Earth

* Etc.

There are two main aspects of statistical analysis:

* the *algorithmic* aspect
* the *inferential* aspect

---

# Averaging

* The distinction begins with the
most basic, and most popular, statistical method, __averaging__

* Suppose we have observed numbers `\(y_1,y_2,\ldots,y_n\)` applying to some phenomenon of
interest, perhaps the automobile accident rates in the `\(n=50\)` states

* We may assume that `\(y_1,\ldots,y_n\)` are i.i.d. realizations of the random variable `\(Y\)`, and 
suppose that our __parameter of interest__ is `\(\mathbb{E}(Y)\)`.

* Averaging is the __algorithm__
`$$\bar{y} = \frac{1}{n}\sum_{i=1}^{n}y_i$$`
How accurate is that number?

---

# Uncertainty

* The standard error provides an __inference__ on the algorithm's accuracy 
`$$\widehat{\mathrm{se}} = \sqrt{\frac{1}{n} \frac{\sum_{i=1}^{n}(y_i - \bar{y})^2}{n-1}}$$`

* Of course, `\(\widehat{\mathrm{se}}\)` is itself an algorithm, which could be (and is) subject
to further inferential analysis concerning its accuracy

* The point is that
the algorithm comes __first__ and the inference follows at a __second__ level of
statistical consideration

---

# Kidney data



```r
kidney &lt;- read.table("https://web.stanford.edu/~hastie/CASI_files/DATA/kidney.txt", header=TRUE, sep=" ")
plot(kidney)
```

&lt;img src="1_Intro_files/figure-html/unnamed-chunk-1-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

# Question of interest

* Data points `\((x_i,y_i)\)` have
been observed for `\(n=157\)` healthy volunteers, with `\(x_i\)` the `\(i\)`th volunteer’s
age in years, and `\(y_i\)` a composite measure of overall kidney function

* Kidney function generally declines with age, as evident in the downward scatter
of the points

* The rate of decline is an important question in kidney
transplantation: in the past, potential donors past age 60 were prohibited,
though, given a shortage of donors, this is no longer enforced

* A potential new donor, aged 65, has appeared, and we wish
to assess his kidney fitness without subjecting him to an arduous series of
medical tests

* The new donor has `\((x^*,y^*)=(65,?)\)`. Suppose that in kidney transplantation we need a value &gt; -4.  Is `\(y^* &gt; -4\)` with high probability?

---

# Regression analysis of the kidney data 

Table 1.1 of CASI: regression line `\(y = \hat{\beta}_0 + \hat{\beta}_1 x\)` estimates of kidney fitness and their standard errors for ages = `\(20,30,40,50,60,70,80\)`


```r
fit &lt;- lm(tot ~ age, data=kidney)
ages &lt;- data.frame(age = seq(20, 80, 10))
res &lt;- predict(fit, newdata=ages, se.fit = TRUE)
knitr::kable(data.frame(age=ages$age, estimate=res$fit,se=res$se.fit), format="html" )
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; age &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; se &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 20 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.2882585 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2066481 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.5023743 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1549648 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 40 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.2835098 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1473983 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.0693940 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.1893143 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 60 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.8552781 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2575947 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 70 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -2.6411623 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.3365586 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 80 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -3.4270465 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.4202260 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

Figure 1.1 of CASI: Kidney fitness vs age for 157 volunteers. The
line is a linear regression fit, showing `\(\pm 2\)` standard errors at
selected values of age


```r
plot(kidney)
abline(fit, col="darkgreen")
for (i in 1:nrow(ages)){
segments(x0=ages$age[i], y0=res$fit[i]-2*res$se.fit[i], y1=res$fit[i]+2*res$se.fit[i], col="darkgreen")
}
```

&lt;img src="1_Intro_files/figure-html/unnamed-chunk-3-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

Figure 1.2 of CASI: Local polynomial fit to the
kidney-fitness data


```r
plot(kidney)
lines(lowess(kidney, f = 1/3), col="darkgreen")
```

&lt;img src="1_Intro_files/figure-html/unnamed-chunk-4-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

Regression splines by using natural cubic spline with 8 degrees of freedom



```r
require(splines)
fit = lm(tot ~ ns(age,8), kidney)
plot(kidney)
lines(kidney$age, fitted(fit), pch="x",col=2)
```

&lt;img src="1_Intro_files/figure-html/unnamed-chunk-5-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

# Confidence and prediction intervals

90% confidence interval for `\(\mathbb{E}(Y^*|x^*=65)\)` 


```r
require(splines)
predict(fit, newdata=data.frame(age=65), interval = "confidence", level=.9)
```

```
        fit       lwr       upr
1 -2.154428 -2.852738 -1.456117
```

90% prediction interval for `\(Y^*|x^*=65\)` 


```r
require(splines)
predict(fit, newdata=data.frame(age=65), interval = "prediction", level=.9)
```

```
        fit       lwr       upr
1 -2.154428 -5.257008 0.9481522
```


---

layout: false
class: inverse, middle, center

# Variable selection

---

# Simulated data

I've generated data from the Gaussian linear model
$$ y = N(1_n \beta_0 + X\beta, \sigma^2I_n)$$
where 

* `\(\underset{n\times 1}{y} = (y_1,\ldots,y_n)'\)` is the response on `\(n\)` observations

* `\(\underset{n\times p}{X}\)` is the design matrix containing the measurements on `\(p\)` explanatory variables 

* `\(\underset{p\times 1}{\beta} = (\beta_1,\ldots,\beta_p)'\)` is the vector of coefficients of interest

* `\(\beta_0\)` and `\(\sigma^2\)` are nuisance parameters

* `\(\underset{n\times 1}{1_n} = (1,1,\ldots,1)'\)` is a vector of ones of length `\(n\)` and `\(\underset{n\times n}{I_n}\)` is the identity matrix

---

# Variable selection 

* The dataset `vs.Rdata` has `\(n=50\)` and `\(p=31\)`


```r
rm(list=ls())
library(repmis)
source_data("https://github.com/aldosolari/SL/blob/master/data/vs.Rdata?raw=true")
```

```
[1] "vs"
```

* The `\(j\)`th explanatory variable is __relevant__ in explaing the response if `\(\beta_j\neq 0\)`, and __irrelevant__  if `\(\beta_j= 0\)`

* The goal is select the relevant variables, i.e. to estimate
`$$S = \{j \in \{1,\ldots,p\}: \beta_j \neq 0\}$$`


* `\(\hat{S} \setminus S\)` are __wrong selections__

* `\(S \setminus \hat{S}\)` are __missed selections__

* What is your `\(\hat{S}\)`?

---

layout: false
class: inverse, middle, center

# Jelly beans cause acne?

---

# Jelly beans cause acne?

* Somebody claims that jelly beans cause acne

* The scientists investigate by designing a randomized experiment with `\(n = 10000\)` subjects
    
-  The subjects are randomly allocated to the jelly beans group ( `\(n_1=5000\)` )
 and to the placebo group ( `\(n_0=5000\)` )
 
- At the end of the month, the presence of acne is recorded (1 if present, 0 otherwise)
 
* Load the dataset `jellybeans.Rdata`


```r
rm(list=ls())
library(repmis)
source_data("https://github.com/aldosolari/SL/blob/master/data/jellybeans.Rdata?raw=true")
```

```
[1] "jellybeans"
```

---

# `\(2\times 2\)` table


```r
n0 = nrow(jellybeans)/2
n1 = n0
y = sum(jellybeans$acne[jellybeans$treatment=="jellybean"])
s = sum(jellybeans$acne) 

tab = matrix(c(
  y, n0-y,
  s-y, n1-s+y
), ncol=2, byrow=TRUE)
colnames(tab) = c("acne","noacne")
rownames(tab) = c("jellybean","placebo")
addmargins(tab)
```

```
          acne noacne   Sum
jellybean  988   4012  5000
placebo    961   4039  5000
Sum       1949   8051 10000
```

Jelly beans cause significantly more acne? 

---

# Fisher's exact test

* Fisher argued for carrying out the hypothesis test conditional
on the marginals of the table

* With the marginals fixed, the
number `\(Y\)` in the upper left cell determines the other three cells by subtraction

|  | Acne | no acne | Sum |
|---|---|---|---|
| Jelly beans | `\(Y\)` | `\(N_{1} - Y\)`  | `\(N_{1}\)` |
| Placebo | `\(S-Y\)` | `\(n_{0} - S + Y\)` | `\(N_{0}\)` |
| Sum   | `\(S\)` | `\(N_{1} + N_{0}-S\)` | `\(N_{1} + N_{0}\)` |

* We need only test whether the observed number `\(y=889\)` is too big under the null hypothesis of no treatment difference

* Under the null hypothesis, the random variable `\(Y|(S,N_{1},N_{0})\)` follows the Hypergeometric Distribution with
`$$\mathrm{Pr}(Y=y|S,N_{1},N_{0}) =  \frac{ {N_{0} \choose S-Y} {N_{1} \choose Y} }{ {N_{1} + N_{0} \choose S} }$$`


---


```r
plot(0:s,dhyper(0:s, n0, n1, s), type="h", xlab="y", ylab="Probability")
points(y,0,col=2,pch=19)
```

&lt;img src="1_Intro_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;" /&gt;

```r
fisher.test(tab, alternative="greater")$p.value
```

```
[1] 0.2557994
```

---

# Color?

* We found no link between jelly beans and acne ( `\(p&gt;0.05\)` )

* But somebody claims that it's only a certain __color__ that causes it

* Jelly beans have 20 colors: purple, brown, pink, blue, teal, salmon, green, turquoise, magenta, yellow, grey, tan, cyan, lilac, mauve, beige, red, black, peach, orange

* Purple jelly beans cause significantly more acne? Brown jelly beans cause significantly more acne? Pink jelly beans cause significantly more acne? Etc.

* Any significant link?

---

layout: false
class: inverse, middle, center

# Which party is correlated with economic success?

---

# Connection between politics and economy

* You're a social scientist with a question: is the U.S. economy affected by whether Republicans or Democrats are in office?

* Try to show that a connection exists, using real data going back to 1948 (monthly data)

* For your results to be publishable in an academic journal, you'll need to prove that they are statistically significant by achieving a low enough `\(p\)`-value

* The more democratic power, the better the economy? Or the other way around?

---

# What about the following analysis?

* `\(Y\)` = GDP 
* `\(X\)` = number of Democratic governors


```r
rm(list=ls())
library(RCurl)
X &lt;- read.csv("https://raw.githubusercontent.com/aldosolari/SL/master/data/X.csv")
Y &lt;- read.csv("https://raw.githubusercontent.com/aldosolari/SL/master/data/Y.csv")
XY = cbind(X[X$date %in% Y$date,],Y[Y$date %in% X$date,-1])
fit = lm(gdp ~ gov_dem, XY)
```

---



```r
plot(gdp ~ gov_dem, XY)
abline(fit)
```

&lt;img src="1_Intro_files/figure-html/unnamed-chunk-13-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---


```r
summary(fit)
```

```

Call:
lm(formula = gdp ~ gov_dem, data = XY)

Residuals:
     Min       1Q   Median       3Q      Max 
-10.5804  -1.6436  -0.1675   1.6873  14.1020 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   1.1374     0.9502   1.197    0.232    
gov_dem       0.1996     0.0340   5.869 1.29e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.312 on 267 degrees of freedom
  (541 observations deleted due to missingness)
Multiple R-squared:  0.1143,	Adjusted R-squared:  0.111 
F-statistic: 34.45 on 1 and 267 DF,  p-value: 1.293e-08
```

---

# Selection

* How do you want to measure economic performance?
    - Employment
    - Inflation
    - __GDP__
    - Stock prices
    
* Which politicians do you want to include?
    - Presidents
    - __Governors__
    - Senators
    - Representatives

* Other options
    - Factor in power (weight more powerful positions more heavily)
    - Exclude recessions (don't include economic recessions)
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightLanguage": "R",
"countIncrementalSlides": false,
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
